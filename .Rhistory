gender = rep(data$gender, 2),
time = c(data$Qualification, data$Final),
event = rep(data$event_name, 2),
year = rep(as.numeric(gsub(".*20", "20", data$date)), 2))
data$athlete <- tolower(data$athlete)
data$event <- tolower(gsub("\\(|\\)", "", data$event))
data
#from https://github.com/lfigil/ifsc-data collected by lfigil on February 1, 2024
#we manually checked whether the data include all world cups and championships from 2007 to 2019
#only missing the 2007 world championships in aviles, which we will add manually: https://ifsc.results.info/#/event/481/
#load files, temporarily removing the manually added entry
files <- list.files("/Users/masonyoungblood/Documents/Work/Fall 2023/BayesFlow Exploring/climbing_times/source_lfigil_ifsc-data")
files <- files[-grep("missing", files)]
#combine into single data frame
data <- do.call(rbind, lapply(files, function(x){
read.csv(paste0("/Users/masonyoungblood/Documents/Work/Fall 2023/BayesFlow Exploring/climbing_times/source_lfigil_ifsc-data/", x))
}))
#restructure so each row is a single time and remove NA values
data <- data.frame(athlete = rep(paste0(data$Name, " ", data$X), 2),
gender = rep(data$gender, 2),
time = c(data$Qualification, data$Final),
event = rep(data$event_name, 2),
year = rep(as.numeric(gsub(".*20", "20", data$date)), 2))
data$athlete <- tolower(data$athlete)
data$event <- tolower(gsub("\\(|\\)", "", data$event))
data$gender[which(data$gender == "Men")] <- "M"
data$gender[which(data$gender == "Women")] <- "W"
data
files[grep("missing", files)]
#load files, temporarily removing the manually added entry
files <- list.files("/Users/masonyoungblood/Documents/Work/Fall 2023/BayesFlow Exploring/climbing_times/source_lfigil_ifsc-data")
missing_file <- files[grep("missing", files)]
files <- files[-grep("missing", files)]
missing_file
#combine into single data frame
data <- do.call(rbind, lapply(files, function(x){
read.csv(paste0("/Users/masonyoungblood/Documents/Work/Fall 2023/BayesFlow Exploring/climbing_times/source_lfigil_ifsc-data/", x))
}))
#restructure so each row is a single time and remove NA values
data <- data.frame(athlete = rep(paste0(data$Name, " ", data$X), 2),
gender = rep(data$gender, 2),
time = c(data$Qualification, data$Final),
event = rep(data$event_name, 2),
year = rep(as.numeric(gsub(".*20", "20", data$date)), 2))
data$athlete <- tolower(data$athlete)
data$event <- tolower(gsub("\\(|\\)", "", data$event))
data$gender[which(data$gender == "Men")] <- "M"
data$gender[which(data$gender == "Women")] <- "W"
#load missing file(s)
missing_file <- read.csv(paste0("/Users/masonyoungblood/Documents/Work/Fall 2023/BayesFlow Exploring/climbing_times/source_lfigil_ifsc-data/", missing_file))
missing_file
#load missing file(s)
missing_file <- read.csv(paste0("/Users/masonyoungblood/Documents/Work/Fall 2023/BayesFlow Exploring/climbing_times/source_lfigil_ifsc-data/", missing_file))
missing_file <- data.frame(athlete = rep(paste0(missing_file$Name, " ", missing_file$X), 2),
gender = rep(missing_file$gender, 2),
time = c(missing_file$qualification, missing_file$final),
event = "aviles_esp_2007",
year = 2007)
#load files, temporarily removing the manually added entry
files <- list.files("/Users/masonyoungblood/Documents/Work/Fall 2023/BayesFlow Exploring/climbing_times/source_lfigil_ifsc-data")
missing_file <- files[grep("missing", files)]
files <- files[-grep("missing", files)]
#load missing file(s)
missing_file <- read.csv(paste0("/Users/masonyoungblood/Documents/Work/Fall 2023/BayesFlow Exploring/climbing_times/source_lfigil_ifsc-data/", missing_file))
missing_file <- data.frame(athlete = rep(paste0(missing_file$Name, " ", missing_file$X), 2),
gender = rep(missing_file$gender, 2),
time = c(missing_file$qualification, missing_file$final),
event = "aviles_esp_2007",
year = 2007)
missing_file
#from https://github.com/lfigil/ifsc-data collected by lfigil on February 1, 2024
#we manually checked whether the data include all world cups and championships from 2007 to 2019
#only missing the 2007 world championships in aviles, which we will add manually: https://ifsc.results.info/#/event/481/
#load files, temporarily removing the manually added entry
files <- list.files("/Users/masonyoungblood/Documents/Work/Fall 2023/BayesFlow Exploring/climbing_times/source_lfigil_ifsc-data")
missing_file <- files[grep("missing", files)]
files <- files[-grep("missing", files)]
#combine into single data frame
data <- do.call(rbind, lapply(files, function(x){
read.csv(paste0("/Users/masonyoungblood/Documents/Work/Fall 2023/BayesFlow Exploring/climbing_times/source_lfigil_ifsc-data/", x))
}))
#restructure so each row is a single time and remove NA values
data <- data.frame(athlete = rep(paste0(data$Name, " ", data$X), 2),
gender = rep(data$gender, 2),
time = c(data$Qualification, data$Final),
event = rep(data$event_name, 2),
year = rep(as.numeric(gsub(".*20", "20", data$date)), 2))
data$athlete <- tolower(data$athlete)
data$event <- tolower(gsub("\\(|\\)", "", data$event))
data$gender[which(data$gender == "Men")] <- "M"
data$gender[which(data$gender == "Women")] <- "W"
#load missing file(s)
missing_file <- read.csv(paste0("/Users/masonyoungblood/Documents/Work/Fall 2023/BayesFlow Exploring/climbing_times/source_lfigil_ifsc-data/", missing_file))
missing_file <- data.frame(athlete = rep(paste0(missing_file$first, " ", missing_file$last), 2),
gender = rep(missing_file$gender, 2),
time = c(missing_file$qualification, missing_file$final),
event = "aviles_esp_2007",
year = 2007)
missing_file
#from https://github.com/lfigil/ifsc-data collected by lfigil on February 1, 2024
#we manually checked whether the data include all world cups and championships from 2007 to 2019
#only missing the 2007 world championships in aviles, which we will add manually: https://ifsc.results.info/#/event/481/
#load files, temporarily removing the manually added entry
files <- list.files("/Users/masonyoungblood/Documents/Work/Fall 2023/BayesFlow Exploring/climbing_times/source_lfigil_ifsc-data")
missing_file <- files[grep("missing", files)]
files <- files[-grep("missing", files)]
#combine into single data frame
data <- do.call(rbind, lapply(files, function(x){
read.csv(paste0("/Users/masonyoungblood/Documents/Work/Fall 2023/BayesFlow Exploring/climbing_times/source_lfigil_ifsc-data/", x))
}))
#restructure so each row is a single time and remove NA values
data <- data.frame(athlete = rep(paste0(data$Name, " ", data$X), 2),
gender = rep(data$gender, 2),
time = c(data$Qualification, data$Final),
event = rep(data$event_name, 2),
year = rep(as.numeric(gsub(".*20", "20", data$date)), 2))
data$athlete <- tolower(data$athlete)
data$athlete <- gsub(" ", "_", data$athlete)
data$event <- tolower(gsub("\\(|\\)", "", data$event))
data$gender[which(data$gender == "Men")] <- "m"
data$gender[which(data$gender == "Women")] <- "w"
data
#load files, temporarily removing the manually added entry
files <- list.files("/Users/masonyoungblood/Documents/Work/Fall 2023/BayesFlow Exploring/climbing_times/source_lfigil_ifsc-data")
missing_file <- files[grep("missing", files)]
files <- files[-grep("missing", files)]
#combine into single data frame
data <- do.call(rbind, lapply(files, function(x){
read.csv(paste0("/Users/masonyoungblood/Documents/Work/Fall 2023/BayesFlow Exploring/climbing_times/source_lfigil_ifsc-data/", x))
}))
substr(data$gender, 1, 1)
#from https://github.com/lfigil/ifsc-data collected by lfigil on February 1, 2024
#we manually checked whether the data include all world cups and championships from 2007 to 2019
#only missing the 2007 world championships in aviles, which we will add manually: https://ifsc.results.info/#/event/481/
#load files, temporarily removing the manually added entry
files <- list.files("/Users/masonyoungblood/Documents/Work/Fall 2023/BayesFlow Exploring/climbing_times/source_lfigil_ifsc-data")
missing_file <- files[grep("missing", files)]
files <- files[-grep("missing", files)]
#combine into single data frame
data <- do.call(rbind, lapply(files, function(x){
read.csv(paste0("/Users/masonyoungblood/Documents/Work/Fall 2023/BayesFlow Exploring/climbing_times/source_lfigil_ifsc-data/", x))
}))
#restructure so each row is a single time and remove NA values
data <- data.frame(athlete = gsub(" ", "_", tolower(rep(paste0(data$Name, " ", data$X), 2))),
gender = tolower(substr(rep(data$gender, 2), 1, 1)),
time = c(data$Qualification, data$Final),
event = tolower(gsub("\\(|\\)", "", rep(data$event_name, 2))),
year = rep(as.numeric(gsub(".*20", "20", data$date)), 2))
data
#load missing file(s)
missing_file <- read.csv(paste0("/Users/masonyoungblood/Documents/Work/Fall 2023/BayesFlow Exploring/climbing_times/source_lfigil_ifsc-data/", missing_file))
#from https://github.com/lfigil/ifsc-data collected by lfigil on February 1, 2024
#we manually checked whether the data include all world cups and championships from 2007 to 2019
#only missing the 2007 world championships in aviles, which we will add manually: https://ifsc.results.info/#/event/481/
#load files, temporarily removing the manually added entry
files <- list.files("/Users/masonyoungblood/Documents/Work/Fall 2023/BayesFlow Exploring/climbing_times/source_lfigil_ifsc-data")
missing_file <- files[grep("missing", files)]
files <- files[-grep("missing", files)]
#combine into single data frame
data <- do.call(rbind, lapply(files, function(x){
read.csv(paste0("/Users/masonyoungblood/Documents/Work/Fall 2023/BayesFlow Exploring/climbing_times/source_lfigil_ifsc-data/", x))
}))
#restructure so each row is a single time and remove NA values
data <- data.frame(athlete = gsub(" ", "_", tolower(rep(paste0(data$Name, " ", data$X), 2))),
gender = tolower(substr(rep(data$gender, 2), 1, 1)),
time = c(data$Qualification, data$Final),
event = tolower(gsub("\\(|\\)", "", rep(data$event_name, 2))),
year = rep(as.numeric(gsub(".*20", "20", data$date)), 2))
#load missing file(s)
missing_file <- read.csv(paste0("/Users/masonyoungblood/Documents/Work/Fall 2023/BayesFlow Exploring/climbing_times/source_lfigil_ifsc-data/", missing_file))
missing_file <- data.frame(athlete = gsub(" ", "_", tolower(rep(paste0(missing_file$first, " ", missing_file$last), 2))),
gender = tolower(rep(missing_file$gender, 2)),
time = c(missing_file$qualification, missing_file$final),
event = "aviles_esp_2007",
year = 2007)
data
missing_file
rbind(missing_file, data)
data <- rbind(missing_file, data)
as.numeric(data$time)
#from https://github.com/lfigil/ifsc-data collected by lfigil on February 1, 2024
#we manually checked whether the data include all world cups and championships from 2007 to 2019
#only missing the 2007 world championships in aviles, which we will add manually: https://ifsc.results.info/#/event/481/
#load files, temporarily removing the manually added entry
files <- list.files("/Users/masonyoungblood/Documents/Work/Fall 2023/BayesFlow Exploring/climbing_times/source_lfigil_ifsc-data")
missing_file <- files[grep("missing", files)]
files <- files[-grep("missing", files)]
#combine into single data frame
data <- do.call(rbind, lapply(files, function(x){
read.csv(paste0("/Users/masonyoungblood/Documents/Work/Fall 2023/BayesFlow Exploring/climbing_times/source_lfigil_ifsc-data/", x))
}))
#restructure so each row is a single time and remove NA values
data <- data.frame(athlete = gsub(" ", "_", tolower(rep(paste0(data$Name, " ", data$X), 2))),
gender = tolower(substr(rep(data$gender, 2), 1, 1)),
time = c(data$Qualification, data$Final),
event = tolower(gsub("\\(|\\)", "", rep(data$event_name, 2))),
year = rep(as.numeric(gsub(".*20", "20", data$date)), 2))
#load missing file and combine with main data
missing_file <- read.csv(paste0("/Users/masonyoungblood/Documents/Work/Fall 2023/BayesFlow Exploring/climbing_times/source_lfigil_ifsc-data/", missing_file))
missing_file <- data.frame(athlete = gsub(" ", "_", tolower(rep(paste0(missing_file$first, " ", missing_file$last), 2))),
gender = tolower(rep(missing_file$gender, 2)),
time = c(missing_file$qualification, missing_file$final),
event = "aviles_esp_2007",
year = 2007)
data <- rbind(missing_file, data)
#reformat times as numeric, which converts failures and false starts into NA, and remove NA values
data$time <- as.numeric(data$time)
data <- data[-which(is.na(data$time)), ]
data
nrow(data)
data$event
length(unique(data$event))
nrow(dat)
nrow(data)
unique(data$athlete)
length(unique(data$athlete))
unique(data$athlete)
match(unique(data$athlete), data$athlete)
data$gender[match(unique(data$athlete), data$athlete)]
table(data$gender[match(unique(data$athlete), data$athlete)])
#from https://github.com/lfigil/ifsc-data collected by lfigil on February 1, 2024
#we manually checked whether the data include all world cups and championships from 2007 to 2019
#only missing the 2007 world championships in aviles, which we will add manually: https://ifsc.results.info/#/event/481/
#load files, temporarily removing the manually added entry
files <- list.files("/Users/masonyoungblood/Documents/Work/Fall 2023/BayesFlow Exploring/climbing_times/source_lfigil_ifsc-data")
missing_file <- files[grep("missing", files)]
files <- files[-grep("missing", files)]
#combine into single data frame
data <- do.call(rbind, lapply(files, function(x){
read.csv(paste0("/Users/masonyoungblood/Documents/Work/Fall 2023/BayesFlow Exploring/climbing_times/source_lfigil_ifsc-data/", x))
}))
#restructure so each row is a single time and remove NA values
data <- data.frame(athlete = gsub(" ", "_", tolower(rep(paste0(data$Name, " ", data$X), 2))),
gender = tolower(substr(rep(data$gender, 2), 1, 1)),
time = c(data$Qualification, data$Final),
event = tolower(gsub("\\(|\\)", "", rep(data$event_name, 2))),
year = rep(as.numeric(gsub(".*20", "20", data$date)), 2))
#load missing file and combine with main data
missing_file <- read.csv(paste0("/Users/masonyoungblood/Documents/Work/Fall 2023/BayesFlow Exploring/climbing_times/source_lfigil_ifsc-data/", missing_file))
missing_file <- data.frame(athlete = gsub(" ", "_", tolower(rep(paste0(missing_file$first, " ", missing_file$last), 2))),
gender = tolower(rep(missing_file$gender, 2)),
time = c(missing_file$qualification, missing_file$final),
event = "aviles_esp_2007",
year = 2007)
data <- rbind(missing_file, data)
#reformat times as numeric, which converts failures and false starts into NA, and remove NA values
data$time <- as.numeric(data$time)
data <- data[-which(is.na(data$time)), ]
nrow(data)
#save data
all_climbing_times <- data
save(all_climbing_times, file = "/Users/masonyoungblood/Documents/Work/Fall 2023/BayesFlow Exploring/climbing_times/all_climbing_times.RData")
readxl::read_xlsx("/Users/masonyoungblood/Documents/Work/Spring 2022/Mourning Warblers/MourningWarblers/data/from_jay/regiolect_distributionsNEW.xlsx")
regiolect_distributions <- readxl::read_xlsx("/Users/masonyoungblood/Documents/Work/Spring 2022/Mourning Warblers/MourningWarblers/data/from_jay/regiolect_distributionsNEW.xlsx")
tolower(regiolect_distributions$type)
duplicated(tolower(regiolect_distributions$type))
which(duplicated(tolower(regiolect_distributions$type)))
paste0(tolower(regiolect_distributions$type), regiolect_distributions$year, regiolect_distributions$regio)
duplicated(paste0(tolower(regiolect_distributions$type), regiolect_distributions$year, regiolect_distributions$regio))
which(duplicated(paste0(tolower(regiolect_distributions$type), regiolect_distributions$year, regiolect_distributions$regio)))
#load in syllable parameters
syllable_params <- readxl::read_xlsx("/Users/masonyoungblood/Documents/Work/Spring 2022/Mourning Warblers/MourningWarblers/data/from_jay/syllable_params.xlsx")
syllable_params$type
paste0(tolower(syllable_params$type), syllable_params$year, syllable_params$regiolect)
which(duplicated(paste0(tolower(syllable_params$type), syllable_params$year, syllable_params$regiolect)))
load("https://github.com/masonyoungblood/TransmissionBias/blob/master/example/data.RData")
load(url("https://github.com/masonyoungblood/TransmissionBias/blob/master/example/data.RData"))
load(url("https://github.com/masonyoungblood/TransmissionBias/raw/master/example/data.RData"))
data$syllable
unique(data$syllable)
load(url("https://github.com/masonyoungblood/linguistic_efficiency/raw/main/docs/data_models/youngblood_lahti_2022.RData"))
data$syllable
load(url("https://github.com/masonyoungblood/linguistic_efficiency/raw/main/docs/data_models/processed_data.RData"))
processed_data$data
runif(20, -1, 1)
data.frame(x = runif(20, -1, 1), y = runif(20, -1, 1))
write.csv(data.frame(x = runif(20, -1, 1), y = runif(20, -1, 1)), file = "/Users/masonyoungblood/Documents/Work/Fall 2023/Song Extinction/touch_designer/coordinates.csv")
?write.csv
write.csv(data.frame(x = runif(20, -1, 1), y = runif(20, -1, 1)), file = "/Users/masonyoungblood/Documents/Work/Fall 2023/Song Extinction/touch_designer/coordinates.csv", row.names = FALSE, col.names = FALSE)
write.csv(data.frame(x = runif(20, -1, 1), y = runif(20, -1, 1)), file = "/Users/masonyoungblood/Documents/Work/Fall 2023/Song Extinction/touch_designer/coordinates.csv", row.names = FALSE, header = FALSE)
write.table(data.frame(x = runif(20, -1, 1), y = runif(20, -1, 1)),
file = "/Users/masonyoungblood/Documents/Work/Fall 2023/Song Extinction/touch_designer/coordinates.csv",
row.names = FALSE, col.names =  = FALSE,
write.table(data.frame(x = runif(20, -1, 1), y = runif(20, -1, 1)),
file = "/Users/masonyoungblood/Documents/Work/Fall 2023/Song Extinction/touch_designer/coordinates.csv",
row.names = FALSE, col.names = FALSE,
sep = ",")
n <- 40
write.table(data.frame(x = runif(n, -1, 1), y = runif(n, -1, 1)),
file = "/Users/masonyoungblood/Documents/Work/Fall 2023/Song Extinction/touch_designer/coordinates.csv",
row.names = FALSE, col.names = FALSE,
sep = ",")
setwd("~/Documents/Work/Spring 2022/Mourning Warblers/MourningWarblers")
library(ggplot2)
library(cowplot)
load("data/priors_and_simulations.RData")
#load in posterior predictions and convert back to original scale for plotting
posts <- jsonlite::read_json("04_bayesflow_analysis/posterior_predictions.json")
posts <- data.frame(do.call(rbind, lapply(1:length(posts), function(x){unlist(posts[[x]])})))
colnames(posts) <- c("n_init", "mu", "dems", "frequency", "content")
posts$n_init <- (posts$n_init*sd(priors_and_simulations[[1]]$n_init)) + mean(priors_and_simulations[[1]]$n_init)
posts$mu <- (posts$mu*sd(priors_and_simulations[[1]]$mu)) + mean(priors_and_simulations[[1]]$mu)
posts$dems <- (posts$dems*sd(priors_and_simulations[[1]]$dems)) + mean(priors_and_simulations[[1]]$dems)
posts$frequency <- (posts$frequency*sd(priors_and_simulations[[1]]$frequency)) + mean(priors_and_simulations[[1]]$frequency)
posts$content <- (posts$content*sd(priors_and_simulations[[1]]$content)) + mean(priors_and_simulations[[1]]$content)
#write function for plotting
plot_abc <- function(posts, param, xlim, xlab){
#specify probability distributions for each parameter
if(param == "n_init"){
param <- 1
prior <- dunif(seq(xlim[1], xlim[2], length.out = 2^10), min = 5000, max = 50000)
}
if(param == "mu"){
param <- 2
prior <- dbeta(seq(xlim[1], xlim[2], length.out = 2^10), 1, 40)
}
if(param == "dems"){
param <- 3
prior <- dunif(seq(xlim[1], xlim[2], length.out = 2^10), min = 2, max = 5)
}
if(param == "frequency"){
param <- 4
prior <- truncnorm::dtruncnorm(seq(xlim[1], xlim[2], length.out = 2^10), a = 0, mean = 1, sd = 0.2)
}
if(param == "content"){
param <- 5
prior <- truncnorm::dtruncnorm(seq(xlim[1], xlim[2], length.out = 2^10), a = 0, mean = 0, sd = 2)
}
#structure data for plotting
data <- data.frame(param = c(seq(xlim[1], xlim[2], length.out = 2^10),
density(posts[, param], n = 2^10, from = xlim[1], to = xlim[2])$x),
density = c(prior,
density(posts[, param], n = 2^10, from = xlim[1], to = xlim[2])$y),
group = factor(c(rep(0, 2^10), rep(1, 2^10))))
#create partial ggplot
if(param == 1){
temp <- ggplot(data = data, aes(x = param, y = density, group = group)) +
geom_line(aes(linetype = group, color = group)) +
scale_x_continuous(expand = c(0, 0), breaks = seq(from = xlim[1], to = xlim[2], length.out = 4)) +
scale_color_manual(values = c("grey", "black")) +
scale_linetype_manual(values = c("solid", "solid")) +
xlab(xlab) + ylab("Density") + theme_linedraw() +
theme(legend.position = "none", plot.margin = margin(t = 5, r = 15, b = 5, l = 5),
panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
axis.text.y = element_text(angle = 90), axis.title.y = element_text(vjust = -4))
} else{
temp <- ggplot(data = data, aes(x = param, y = density, group = group)) +
geom_line(aes(linetype = group, color = group)) +
scale_x_continuous(expand = c(0, 0), breaks = seq(from = xlim[1], to = xlim[2], length.out = 4),
labels = scales::number_format(accuracy = 0.01, decimal.mark = '.')) +
scale_color_manual(values = c("grey", "black")) +
scale_linetype_manual(values = c("solid", "solid")) +
xlab(xlab) + ylab("Density") + theme_linedraw() +
theme(legend.position = "none", plot.margin = margin(t = 5, r = 15, b = 5, l = 5),
panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
axis.text.y = element_text(angle = 90), axis.title.y = element_text(vjust = -4))
}
#add the relevant y axis labels for plotting
if(param %in% c(1, 2)){
temp <- temp + scale_y_continuous(expand = c(0, 0), breaks = c(max(data$density)), limits = c(0, max(data$density)), labels = scales::scientific_format(digits = 2))
}
if(param %in% c(4, 5)){
temp <- temp + scale_y_continuous(expand = c(0, 0), breaks = c(max(data$density)), limits = c(0, max(data$density)), labels = round(max(data$density), digits = 1))
}
#return object
return(temp)
}
plot_abc(posts, "frequency", c(0, 2), "Frequency Bias")
plot_abc(posts, "frequency", c(0, 3), "Frequency Bias")
plot_abc(posts, "frequency", c(0, 3), "Frequency Bias")
plot_abc(posts, "content", c(0, 5), "Content Bias")
plot_abc(posts, "content", c(0, 6), "Content Bias")
#write function for plotting
plot_abc <- function(posts, param, xlim, xlab){
#specify probability distributions for each parameter
if(param == "n_init"){
param <- 1
prior <- dunif(seq(xlim[1], xlim[2], length.out = 2^10), min = 5000, max = 50000)
}
if(param == "mu"){
param <- 2
prior <- dbeta(seq(xlim[1], xlim[2], length.out = 2^10), 1, 40)
}
if(param == "dems"){
param <- 3
prior <- dunif(seq(xlim[1], xlim[2], length.out = 2^10), min = 2, max = 5)
}
if(param == "frequency"){
param <- 4
prior <- truncnorm::dtruncnorm(seq(xlim[1], xlim[2], length.out = 2^10), a = 0, mean = 1, sd = 0.2)
}
if(param == "content"){
param <- 5
prior <- truncnorm::dtruncnorm(seq(xlim[1], xlim[2], length.out = 2^10), a = 0, mean = 0, sd = 2)
}
#structure data for plotting
data <- data.frame(param = c(seq(xlim[1], xlim[2], length.out = 2^10),
density(posts[, param], n = 2^10, from = xlim[1], to = xlim[2])$x),
density = c(prior,
density(posts[, param], n = 2^10, from = xlim[1], to = xlim[2])$y),
group = factor(c(rep(0, 2^10), rep(1, 2^10))))
#create partial ggplot
if(param %in% c(1, 3, 4)){
temp <- ggplot(data = data, aes(x = param, y = density, group = group)) +
geom_line(aes(linetype = group, color = group)) +
scale_x_continuous(expand = c(0, 0), breaks = seq(from = xlim[1], to = xlim[2], length.out = 4)) +
scale_color_manual(values = c("grey", "black")) +
scale_linetype_manual(values = c("solid", "solid")) +
xlab(xlab) + ylab("Density") + theme_linedraw() +
theme(legend.position = "none", plot.margin = margin(t = 5, r = 15, b = 5, l = 5),
panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
axis.text.y = element_text(angle = 90), axis.title.y = element_text(vjust = -4))
} else{
temp <- ggplot(data = data, aes(x = param, y = density, group = group)) +
geom_line(aes(linetype = group, color = group)) +
scale_x_continuous(expand = c(0, 0), breaks = seq(from = xlim[1], to = xlim[2], length.out = 4),
labels = scales::number_format(accuracy = 0.01, decimal.mark = '.')) +
scale_color_manual(values = c("grey", "black")) +
scale_linetype_manual(values = c("solid", "solid")) +
xlab(xlab) + ylab("Density") + theme_linedraw() +
theme(legend.position = "none", plot.margin = margin(t = 5, r = 15, b = 5, l = 5),
panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
axis.text.y = element_text(angle = 90), axis.title.y = element_text(vjust = -4))
}
#add the relevant y axis labels for plotting
if(param %in% c(1, 2)){
temp <- temp + scale_y_continuous(expand = c(0, 0), breaks = c(max(data$density)), limits = c(0, max(data$density)), labels = scales::scientific_format(digits = 2))
}
if(param %in% c(4, 5)){
temp <- temp + scale_y_continuous(expand = c(0, 0), breaks = c(max(data$density)), limits = c(0, max(data$density)), labels = round(max(data$density), digits = 1))
}
#return object
return(temp)
}
plot_abc(posts, "content", c(0, 6), "Content Bias")
plot_abc(posts, "frequency", c(0, 3), "Frequency Bias")
#write function for plotting
plot_abc <- function(posts, param, xlim, xlab){
#specify probability distributions for each parameter
if(param == "n_init"){
param <- 1
prior <- dunif(seq(xlim[1], xlim[2], length.out = 2^10), min = 5000, max = 50000)
}
if(param == "mu"){
param <- 2
prior <- dbeta(seq(xlim[1], xlim[2], length.out = 2^10), 1, 40)
}
if(param == "dems"){
param <- 3
prior <- dunif(seq(xlim[1], xlim[2], length.out = 2^10), min = 2, max = 5)
}
if(param == "frequency"){
param <- 4
prior <- truncnorm::dtruncnorm(seq(xlim[1], xlim[2], length.out = 2^10), a = 0, mean = 1, sd = 0.2)
}
if(param == "content"){
param <- 5
prior <- truncnorm::dtruncnorm(seq(xlim[1], xlim[2], length.out = 2^10), a = 0, mean = 0, sd = 2)
}
#structure data for plotting
data <- data.frame(param = c(seq(xlim[1], xlim[2], length.out = 2^10),
density(posts[, param], n = 2^10, from = xlim[1], to = xlim[2])$x),
density = c(prior,
density(posts[, param], n = 2^10, from = xlim[1], to = xlim[2])$y),
group = factor(c(rep(0, 2^10), rep(1, 2^10))))
#create partial ggplot
if(param %in% c(1, 3, 4, 5)){
temp <- ggplot(data = data, aes(x = param, y = density, group = group)) +
geom_line(aes(linetype = group, color = group)) +
scale_x_continuous(expand = c(0, 0), breaks = seq(from = xlim[1], to = xlim[2], length.out = 4)) +
scale_color_manual(values = c("grey", "black")) +
scale_linetype_manual(values = c("solid", "solid")) +
xlab(xlab) + ylab("Density") + theme_linedraw() +
theme(legend.position = "none", plot.margin = margin(t = 5, r = 15, b = 5, l = 5),
panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
axis.text.y = element_text(angle = 90), axis.title.y = element_text(vjust = -4))
} else{
temp <- ggplot(data = data, aes(x = param, y = density, group = group)) +
geom_line(aes(linetype = group, color = group)) +
scale_x_continuous(expand = c(0, 0), breaks = seq(from = xlim[1], to = xlim[2], length.out = 4),
labels = scales::number_format(accuracy = 0.01, decimal.mark = '.')) +
scale_color_manual(values = c("grey", "black")) +
scale_linetype_manual(values = c("solid", "solid")) +
xlab(xlab) + ylab("Density") + theme_linedraw() +
theme(legend.position = "none", plot.margin = margin(t = 5, r = 15, b = 5, l = 5),
panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
axis.text.y = element_text(angle = 90), axis.title.y = element_text(vjust = -4))
}
#add the relevant y axis labels for plotting
if(param %in% c(1, 2)){
temp <- temp + scale_y_continuous(expand = c(0, 0), breaks = c(max(data$density)), limits = c(0, max(data$density)), labels = scales::scientific_format(digits = 2))
}
if(param %in% c(4, 5)){
temp <- temp + scale_y_continuous(expand = c(0, 0), breaks = c(max(data$density)), limits = c(0, max(data$density)), labels = round(max(data$density), digits = 1))
}
#return object
return(temp)
}
plot_abc(posts, "content", c(0, 6), "Content Bias")
#create plot for each parameter to be included in main panel
n_init_plot <- plot_abc(posts, "n_init", c(5000, 50000), "Population Size")
mu_plot <- plot_abc(posts, "mu", c(0, 0.1), "Innovation Rate")
content_plot <- plot_abc(posts, "content", c(0, 6), "Content Bias")
frequency_plot <- plot_abc(posts, "frequency", c(0, 3), "Frequency Bias")
#save figure
png(paste0("figures/main_posteriors.png"), width = 7, height = 5, units = "in", res = 600)
plot_grid(n_init_plot + theme(legend.position = "none"),
mu_plot + theme(legend.position = "none"),
frequency_plot + theme(legend.position = "none") + geom_vline(xintercept = 1, linetype = "dashed"),
content_plot + theme(legend.position = "none"),
nrow = 2, labels = c("A", "B", "C", "D"))
dev.off()
